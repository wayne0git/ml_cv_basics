{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "ec82b70722ec4960ad5b0c007b2ddc33": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2ed706e8c0d04501b87a2296c3580527",
              "IPY_MODEL_3b6c68677d9d4270aaf7dde0d64bee6e",
              "IPY_MODEL_deed18890cde474eb70ad400ff427c59",
              "IPY_MODEL_39f16509ff71435d9ec4c0cbb7a02bdb",
              "IPY_MODEL_dda95793e51f4705aae69512ea714732"
            ],
            "layout": "IPY_MODEL_2f343899ca0b43cc991aba69f9dacbac"
          }
        },
        "2ed706e8c0d04501b87a2296c3580527": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d1417c7c620a4765a0091972351c3ad6",
            "placeholder": "​",
            "style": "IPY_MODEL_09027bb3b466457299130641f334ce35",
            "value": "<center> <img\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svg\nalt='Hugging Face'> <br> Copy a token from <a\nhref=\"https://huggingface.co/settings/tokens\" target=\"_blank\">your Hugging Face\ntokens page</a> and paste it below. <br> Immediately click login after copying\nyour token or it might be stored in plain text in this notebook file. </center>"
          }
        },
        "3b6c68677d9d4270aaf7dde0d64bee6e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "PasswordModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "PasswordModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "PasswordView",
            "continuous_update": true,
            "description": "Token:",
            "description_tooltip": null,
            "disabled": false,
            "layout": "IPY_MODEL_173defbd24d14ae1b74d223381effc3c",
            "placeholder": "​",
            "style": "IPY_MODEL_856f5eebc3e34b678745dd05814eaf4b",
            "value": ""
          }
        },
        "deed18890cde474eb70ad400ff427c59": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "CheckboxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "CheckboxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "CheckboxView",
            "description": "Add token as git credential?",
            "description_tooltip": null,
            "disabled": false,
            "indent": true,
            "layout": "IPY_MODEL_7113029df904412e9a6dc7b62c79f9c1",
            "style": "IPY_MODEL_d139690710ad4281ae806f4fa048a73c",
            "value": false
          }
        },
        "39f16509ff71435d9ec4c0cbb7a02bdb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ButtonView",
            "button_style": "",
            "description": "Login",
            "disabled": false,
            "icon": "",
            "layout": "IPY_MODEL_8957f53b9d494d07a99d9bfce2ddb4d0",
            "style": "IPY_MODEL_d03d24da8bf2474a8fb2c220b392b36b",
            "tooltip": ""
          }
        },
        "dda95793e51f4705aae69512ea714732": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a629d80506634c31a9ff570c3562a568",
            "placeholder": "​",
            "style": "IPY_MODEL_4d4d04831ca64c06a345b8c94143603f",
            "value": "\n<b>Pro Tip:</b> If you don't already have one, you can create a dedicated\n'notebooks' token with 'write' access, that you can then easily reuse for all\nnotebooks. </center>"
          }
        },
        "2f343899ca0b43cc991aba69f9dacbac": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": "center",
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "flex",
            "flex": null,
            "flex_flow": "column",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "50%"
          }
        },
        "d1417c7c620a4765a0091972351c3ad6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "09027bb3b466457299130641f334ce35": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "173defbd24d14ae1b74d223381effc3c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "856f5eebc3e34b678745dd05814eaf4b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7113029df904412e9a6dc7b62c79f9c1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d139690710ad4281ae806f4fa048a73c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8957f53b9d494d07a99d9bfce2ddb4d0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d03d24da8bf2474a8fb2c220b392b36b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "button_color": null,
            "font_weight": ""
          }
        },
        "a629d80506634c31a9ff570c3562a568": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4d4d04831ca64c06a345b8c94143603f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/wayne0git/ml_cv_basics/blob/master/image_synthesis/stable_diffusion.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Stable Diffusion Examples\n",
        "#### Adapted from: https://colab.research.google.com/github/huggingface/notebooks/blob/main/diffusers/stable_diffusion.ipynb"
      ],
      "metadata": {
        "id": "gVJOhMKfFc2u"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Environment Preparation"
      ],
      "metadata": {
        "id": "305NAsZFLgxf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Install Library"
      ],
      "metadata": {
        "id": "4iWtYIUFNdiP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install diffusers==0.2.4\n",
        "!pip install transformers scipy ftfy\n",
        "!pip install \"ipywidgets>=7,<8\""
      ],
      "metadata": {
        "collapsed": true,
        "id": "4QuVPOmSFhRj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Import Library"
      ],
      "metadata": {
        "id": "-d9DZR-hMZcn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "from PIL import Image, ImageDraw\n",
        "from base64 import b64encode\n",
        "from tqdm.auto import tqdm"
      ],
      "metadata": {
        "id": "lJMhs-hGMhuv"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import HTML\n",
        "from google.colab import output"
      ],
      "metadata": {
        "id": "sZU5jc0nMqMY"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import autocast\n",
        "from torch.nn import functional as F\n",
        "\n",
        "from diffusers import StableDiffusionPipeline, AutoencoderKL\n",
        "from diffusers import UNet2DConditionModel, PNDMScheduler, LMSDiscreteScheduler\n",
        "from diffusers.schedulers.scheduling_ddim import DDIMScheduler\n",
        "\n",
        "from transformers import CLIPTextModel, CLIPTokenizer"
      ],
      "metadata": {
        "id": "S6548QtpMtpe"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from huggingface_hub import notebook_login"
      ],
      "metadata": {
        "id": "qUc06HFmMOH_"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Constant"
      ],
      "metadata": {
        "id": "4cxxHsazNDMH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = 'cuda'"
      ],
      "metadata": {
        "id": "n6vX7kaKNFZP"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Configure Colab"
      ],
      "metadata": {
        "id": "f_192xbuNSpn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "output.enable_custom_widget_manager()"
      ],
      "metadata": {
        "id": "YHB1DrJoNUzO"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Login huggingface_hub"
      ],
      "metadata": {
        "id": "pKUPlXkjNoN_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "notebook_login()"
      ],
      "metadata": {
        "id": "Mb-u1yDAJ23R",
        "outputId": "b1cfa0a4-9fc2-4c7e-dabe-81c1eddcd5e2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 359,
          "referenced_widgets": [
            "ec82b70722ec4960ad5b0c007b2ddc33",
            "2ed706e8c0d04501b87a2296c3580527",
            "3b6c68677d9d4270aaf7dde0d64bee6e",
            "deed18890cde474eb70ad400ff427c59",
            "39f16509ff71435d9ec4c0cbb7a02bdb",
            "dda95793e51f4705aae69512ea714732",
            "2f343899ca0b43cc991aba69f9dacbac",
            "d1417c7c620a4765a0091972351c3ad6",
            "09027bb3b466457299130641f334ce35",
            "173defbd24d14ae1b74d223381effc3c",
            "856f5eebc3e34b678745dd05814eaf4b",
            "7113029df904412e9a6dc7b62c79f9c1",
            "d139690710ad4281ae806f4fa048a73c",
            "8957f53b9d494d07a99d9bfce2ddb4d0",
            "d03d24da8bf2474a8fb2c220b392b36b",
            "a629d80506634c31a9ff570c3562a568",
            "4d4d04831ca64c06a345b8c94143603f"
          ]
        }
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Token is valid.\n",
            "Your token has been saved to /root/.huggingface/token\n",
            "Login successful\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Utility Function"
      ],
      "metadata": {
        "id": "lU7CFuaCYXZq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def image_grid(imgs, rows, cols):\n",
        "  assert len(imgs) == rows * cols\n",
        "\n",
        "  w, h = imgs[0].size\n",
        "  grid = Image.new('RGB', size=(cols * w, rows * h))\n",
        "  grid_w, grid_h = grid.size\n",
        "   \n",
        "  for i, img in enumerate(imgs):\n",
        "    grid.paste(img, box=(i % cols * w, i // cols * h))\n",
        "\n",
        "  return grid"
      ],
      "metadata": {
        "id": "oEXRVPQRLXDm"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def imgs_to_video(imgs, video_name='video.mp4', fps=15):\n",
        "  # Source: https://stackoverflow.com/questions/52414148/turn-pil-images-into-video-on-linux\n",
        "  video_dims = (imgs[0].width, imgs[0].height)\n",
        "  fourcc = cv2.VideoWriter_fourcc(*'DIVX')    \n",
        "  video = cv2.VideoWriter(video_name, fourcc, fps, video_dims)\n",
        "\n",
        "  for img in imgs:\n",
        "    tmp_img = img.copy()\n",
        "    video.write(cv2.cvtColor(np.array(tmp_img), cv2.COLOR_RGB2BGR))\n",
        "\n",
        "  video.release()"
      ],
      "metadata": {
        "id": "5UmvYYMKfpU-"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def display_video(file_path, width=512):\n",
        "  # Compress video\n",
        "  compressed_vid_path = 'comp_' + file_path\n",
        "  if os.path.exists(compressed_vid_path):\n",
        "    os.remove(compressed_vid_path)\n",
        "\n",
        "  os.system(f'ffmpeg -i {file_path} -vcodec libx264 {compressed_vid_path}')\n",
        "\n",
        "  # Base64 encode\n",
        "  mp4 = open(compressed_vid_path, 'rb').read()\n",
        "  data_url = 'data:simul2/mp4;base64,' + b64encode(mp4).decode()\n",
        "\n",
        "  return HTML(\"\"\"\n",
        "    <video width={} controls>\n",
        "          <source src=\"{}\" type=\"video/mp4\">\n",
        "    </video>\n",
        "    \"\"\".format(width, data_url))"
      ],
      "metadata": {
        "id": "YLN7c6QsfqIO"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Run stable diffusion (Simple)"
      ],
      "metadata": {
        "id": "sQAcPVifT5g-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initalize stable diffusion model\n",
        "# Should login & visit https://huggingface.co/CompVis/stable-diffusion-v1-4,\n",
        "# Read, accept and acknowledge the LICENSE\n",
        "pipe = StableDiffusionPipeline.from_pretrained('CompVis/stable-diffusion-v1-4', revision='fp16',\n",
        "                          torch_dtype=torch.float16, use_auth_token=True)\n",
        "pipe = pipe.to(device)"
      ],
      "metadata": {
        "id": "rJ50eLT9KJnn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Parameter\n",
        "width, height = 512, 512\n",
        "n_step = 50\n",
        "prompts = ['Cute shiba inu dog'] * 3\n",
        "\n",
        "# Run stable diffusion\n",
        "with autocast(device):\n",
        "  result = pipe(prompts, width=width, height=height, num_inference_steps=n_step)\n",
        "  images = result['sample']\n",
        "\n",
        "# Show result\n",
        "image_grid(images, rows=1, cols=3)"
      ],
      "metadata": {
        "id": "f-R85DLFKe2H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Run stable diffusion (Pipeline)"
      ],
      "metadata": {
        "id": "Jemb6sFxZzQo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Load Model"
      ],
      "metadata": {
        "id": "cpoO6g7rbHqo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Load the autoencoder model which will be used to decode the latents into image space. \n",
        "vae = AutoencoderKL.from_pretrained('CompVis/stable-diffusion-v1-4', subfolder='vae', use_auth_token=True)\n",
        "vae = vae.to(device)"
      ],
      "metadata": {
        "id": "68WKQywdZ2Vx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. Load the tokenizer and text encoder to tokenize and encode the text. \n",
        "tokenizer = CLIPTokenizer.from_pretrained('openai/clip-vit-large-patch14')\n",
        "text_encoder = CLIPTextModel.from_pretrained('openai/clip-vit-large-patch14')\n",
        "text_encoder = text_encoder.to(device)"
      ],
      "metadata": {
        "id": "kO62SE0faOdK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 3. The UNet model for generating the latents.\n",
        "unet = UNet2DConditionModel.from_pretrained('CompVis/stable-diffusion-v1-4', subfolder='unet', use_auth_token=True)\n",
        "unet = unet.to(device)"
      ],
      "metadata": {
        "id": "byFbzqAdag2o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 4. Create a scheduler for inference\n",
        "scheduler = LMSDiscreteScheduler(beta_start=0.00085, beta_end=0.012, beta_schedule='scaled_linear', num_train_timesteps=1000)"
      ],
      "metadata": {
        "id": "zvSYM_B1OdPJ"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Function block of stable diffusion"
      ],
      "metadata": {
        "id": "46rHPIo3bU7A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_text_embeds(prompt):\n",
        "  # Tokenize text and get embeddings\n",
        "  text_input = tokenizer(prompt, padding='max_length', max_length=tokenizer.model_max_length,\n",
        "               truncation=True, return_tensors='pt')\n",
        "  with torch.no_grad():\n",
        "    text_embeddings = text_encoder(text_input.input_ids.to(device))[0]\n",
        "\n",
        "  # Do the same for unconditional embeddings\n",
        "  uncond_input = tokenizer([''] * len(prompt), padding='max_length', max_length=tokenizer.model_max_length,\n",
        "                return_tensors='pt')\n",
        "  with torch.no_grad():\n",
        "    uncond_embeddings = text_encoder(uncond_input.input_ids.to(device))[0]\n",
        "\n",
        "  # Cat for final embeddings (2, 77, 768)\n",
        "  text_embeddings = torch.cat([uncond_embeddings, text_embeddings])\n",
        "\n",
        "  return text_embeddings"
      ],
      "metadata": {
        "id": "pPG1gZlWO2HW"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Test get_text_embeds\n",
        "test_embeds = get_text_embeds(['Cute shiba inu dog'])\n",
        "print(test_embeds.shape)"
      ],
      "metadata": {
        "id": "xl84psc2b6s_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def produce_latents(text_embeddings, height=512, width=512, \n",
        "           num_inference_steps=50, guidance_scale=7.5, latents=None,\n",
        "           return_all_latents=False, start_step=0):\n",
        "  # Initialize latent (1, 4, 64, 64)\n",
        "  if latents is None:\n",
        "    latents = torch.randn((text_embeddings.shape[0] // 2, unet.in_channels, height // 8, width // 8))\n",
        "  latents = latents.to(device)\n",
        "\n",
        "  scheduler.set_timesteps(num_inference_steps)\n",
        "  latents = latents * scheduler.sigmas[0]\n",
        "\n",
        "  # Diffusion process given start step\n",
        "  if start_step > 0:\n",
        "    start_timestep = scheduler.timesteps[start_step]\n",
        "    start_timesteps = start_timestep.repeat(latents.shape[0]).long()\n",
        "\n",
        "    noise = torch.randn_like(latents)\n",
        "    latents = scheduler.add_noise(latents, noise, start_timesteps)\n",
        "\n",
        "  # Reverse the diffusion process iteratively\n",
        "  latent_hist = [latents]\n",
        "\n",
        "  with autocast('cuda'):\n",
        "    for i, t in tqdm(enumerate(scheduler.timesteps[start_step:])):\n",
        "      # expand the latents if we are doing classifier-free guidance to avoid doing two forward passes.\n",
        "      latent_model_input = torch.cat([latents] * 2)\n",
        "      sigma = scheduler.sigmas[i]\n",
        "      latent_model_input = latent_model_input / ((sigma**2 + 1) ** 0.5)\n",
        "\n",
        "      # predict the noise residual\n",
        "      with torch.no_grad():\n",
        "        noise_pred = unet(latent_model_input, t, encoder_hidden_states=text_embeddings)['sample']\n",
        "\n",
        "      # perform guidance\n",
        "      noise_pred_uncond, noise_pred_text = noise_pred.chunk(2)\n",
        "      noise_pred = noise_pred_uncond + guidance_scale * (noise_pred_text - noise_pred_uncond)\n",
        "\n",
        "      # compute the previous noisy sample x_t -> x_t-1\n",
        "      latents = scheduler.step(noise_pred, i, latents)['prev_sample']\n",
        "      latent_hist.append(latents)\n",
        "  \n",
        "  if return_all_latents:\n",
        "    all_latents = torch.cat(latent_hist, dim=0)\n",
        "    return all_latents      \n",
        "  else:\n",
        "    return latents"
      ],
      "metadata": {
        "id": "LRz09rdqQVEb"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Test produce_latents\n",
        "test_latents = produce_latents(test_embeds)\n",
        "print(test_latents.shape)"
      ],
      "metadata": {
        "id": "Hh-4Unj-cvn9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def decode_img_latents(latents):\n",
        "  # Normalization\n",
        "  latents = latents / 0.18215\n",
        "\n",
        "  # Decode\n",
        "  with torch.no_grad():\n",
        "    imgs = vae.decode(latents)\n",
        "\n",
        "  # Tensor => Images\n",
        "  imgs = (imgs / 2 + 0.5).clamp(0, 1)\n",
        "  imgs = imgs.detach().cpu().permute(0, 2, 3, 1).numpy()\n",
        "  imgs = (imgs * 255).round().astype('uint8')\n",
        "  pil_images = [Image.fromarray(image) for image in imgs]\n",
        "\n",
        "  return pil_images"
      ],
      "metadata": {
        "id": "KbmrA5ocR42W"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Test decode_img_latents\n",
        "imgs = decode_img_latents(test_latents)\n",
        "imgs[0]"
      ],
      "metadata": {
        "id": "_nFbemaUeA_X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Stable Diffusion Pipeline"
      ],
      "metadata": {
        "id": "CA4twZyQe1Vn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def prompt_to_img(prompts, height=512, width=512, num_inference_steps=50,\n",
        "          guidance_scale=7.5, latents=None,\n",
        "          return_all_latents=False, batch_size=2, start_step=0):\n",
        "  # Prompts -> text embeds\n",
        "  text_embeds = get_text_embeds(prompts)\n",
        "\n",
        "  # Text embeds -> img latents\n",
        "  latents = produce_latents(text_embeds, height=height, width=width, latents=latents,\n",
        "                 num_inference_steps=num_inference_steps, guidance_scale=guidance_scale,\n",
        "                 return_all_latents=return_all_latents, start_step=start_step)\n",
        "  \n",
        "  # Img latents -> imgs\n",
        "  all_imgs = []\n",
        "  for i in tqdm(range(0, len(latents), batch_size)):\n",
        "    imgs = decode_img_latents(latents[i:i+batch_size])\n",
        "    all_imgs.extend(imgs)\n",
        "\n",
        "  return all_imgs"
      ],
      "metadata": {
        "id": "OnALITW_SO6i"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Image"
      ],
      "metadata": {
        "id": "dNniAG21kfG1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt_to_img(['Cute shiba inu dog'], 512, 512, 50)[0]"
      ],
      "metadata": {
        "id": "9s8QKfjeSV-O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Video"
      ],
      "metadata": {
        "id": "KBDsuZ6vkhat"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "video_frames = prompt_to_img(['Cute shiba inu dog'], num_inference_steps=40, return_all_latents=True)\n",
        "imgs_to_video(video_frames, 'test.mp4')\n",
        "display_video('test.mp4')"
      ],
      "metadata": {
        "id": "DQFAJ9zpkiw1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Similar Img"
      ],
      "metadata": {
        "id": "eQuA_IcwUBID"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def perturb_latents(latents, scale=0.1):\n",
        "  noise = torch.randn_like(latents)\n",
        "  new_latents = (1 - scale) * latents + scale * noise\n",
        "\n",
        "  return (new_latents - new_latents.mean()) / new_latents.std()"
      ],
      "metadata": {
        "id": "JEU5s-dYUsaF"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create image from random noise\n",
        "latents = torch.randn((1, unet.in_channels, 64, 64))\n",
        "prompt_to_img(['Cute shiba inu dog'], 512, 512, 50, latents=latents)[0]"
      ],
      "metadata": {
        "id": "NGa9BlnVUBkx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create image from perturbed random noise\n",
        "new_latents = perturb_latents(latents, 0.1)\n",
        "prompt_to_img(['Cute shiba inu dog'], 512, 512, 50, latents=new_latents)[0]"
      ],
      "metadata": {
        "id": "pFgvbagcUt5j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Img-to-Img"
      ],
      "metadata": {
        "id": "4RnIePDcVDgg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def encode_img_latents(imgs):\n",
        "  img_arr = np.stack([np.array(img) for img in imgs], axis=0)\n",
        "  img_arr = img_arr / 255.0\n",
        "  img_arr = torch.from_numpy(img_arr).float().permute(0, 3, 1, 2)\n",
        "  img_arr = 2 * (img_arr - 0.5)\n",
        "\n",
        "  latent_dists = vae.encode(img_arr.to(device))\n",
        "  latent_samples = latent_dists.sample()\n",
        "  latent_samples *= 0.18215\n",
        "\n",
        "  return latent_samples"
      ],
      "metadata": {
        "id": "F4NdNyhmVSj_"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create reference image\n",
        "img = prompt_to_img(['Cute shiba inu dog'], 512, 512, num_inference_steps=30)[0]\n",
        "img"
      ],
      "metadata": {
        "id": "CFQUCe9rVDpY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Encode reference image\n",
        "img_latents = encode_img_latents([img])"
      ],
      "metadata": {
        "id": "tlwbHH7qVcx0"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create new image based on reference image (May need different scheduler)\n",
        "prompt_to_img(['Cute shiba inu dog under star sky'], 512, 512, num_inference_steps=30, latents=img_latents,start_step=20)[0]"
      ],
      "metadata": {
        "id": "43uONiOEW4Pc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "qT2JgHGioMy-"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}