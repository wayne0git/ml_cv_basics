{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "yolo_v5_train_example_pytorch.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPIYwYJpLAfUUhEMSAKusm2",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/wayne0git/ml_cv_basics/blob/master/object_detection/yolo_v5_train_example_pytorch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# YOLO v5 Training Example Code\n",
        "- https://learnopencv.com/custom-object-detection-training-using-yolov5/\n",
        "\n"
      ],
      "metadata": {
        "id": "zCFf6tE3MhcS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Environment Preparation"
      ],
      "metadata": {
        "id": "LDnDkkOEMzN8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### YOLO v5"
      ],
      "metadata": {
        "id": "8yNOMhroM45u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os"
      ],
      "metadata": {
        "id": "2vpR6hr1M8LI"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pdggsCclLo69"
      },
      "outputs": [],
      "source": [
        "if not os.path.exists('yolov5'):\n",
        "    !git clone https://github.com/ultralytics/yolov5.git"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd yolov5"
      ],
      "metadata": {
        "id": "VqI6OxIGNVJU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -r requirements.txt"
      ],
      "metadata": {
        "id": "I72LwU-1NaCV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Preparation"
      ],
      "metadata": {
        "id": "hMmO-GMVNrym"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Download Traffic vehicles Object Detection (Kaggle)"
      ],
      "metadata": {
        "id": "xu9AAKtEN15M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests"
      ],
      "metadata": {
        "id": "r656_7RaNuU0"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ZIP_FPATH = 'data/traffic-vehicles-object-detection.zip'\n",
        "DATA_DIR = 'data'"
      ],
      "metadata": {
        "id": "yRrdqHZTOtlK"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def download_file(url, save_name):\n",
        "    if not os.path.exists(save_name):\n",
        "        file = requests.get(url)\n",
        "        open(save_name, 'wb').write(file.content)\n",
        "    else: \n",
        "        print('File already present, skipping download...')"
      ],
      "metadata": {
        "id": "7hOsgx05OC5s"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "download_file(\n",
        "    'https://learnopencv.s3.us-west-2.amazonaws.com/traffic-vehicles-object-detection.zip',\n",
        "    ZIP_FPATH\n",
        ")"
      ],
      "metadata": {
        "id": "WHpXD_TSONOq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip -q {ZIP_FPATH} -d {DATA_DIR}"
      ],
      "metadata": {
        "id": "RcBjszhHPGBf"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create data YAML file"
      ],
      "metadata": {
        "id": "p_H7SHrOTASl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile data/data.yaml\n",
        "path: \"data/Traffic Dataset\" # Path relative to the `train.py` script. \n",
        "train: images/train \n",
        "val: images/val \n",
        "\n",
        "# Classes\n",
        "nc: 7\n",
        "names: [\n",
        "    \"Car\", \"Number Plate\", \"Blur Number Plate\", \"Two Wheeler\", \"Auto\", \"Bus\", \"Truck\"\n",
        "]"
      ],
      "metadata": {
        "id": "_QBf8wMgTCel"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data visualization"
      ],
      "metadata": {
        "id": "PghiEuEoTfjk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import glob\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "bbjopnE2WaH6"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class_names = [\"Car\", \"Number Plate\", \"Blur Number Plate\", \"Two Wheeler\", \"Auto\", \"Bus\", \"Truck\"] "
      ],
      "metadata": {
        "id": "OBqFKPzMTg38"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to convert bounding boxes in YOLO format to xmin, ymin, xmax, ymax.\n",
        "def yolo2bbox(bboxes):\n",
        "    xmin, ymin = bboxes[0]-bboxes[2]/2, bboxes[1]-bboxes[3]/2\n",
        "    xmax, ymax = bboxes[0]+bboxes[2]/2, bboxes[1]+bboxes[3]/2\n",
        "    return xmin, ymin, xmax, ymax"
      ],
      "metadata": {
        "id": "dCMbmzsBTqz1"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_box(image, bboxes, labels):\n",
        "    # Need the image height and width to denormalize the bounding box coordinates\n",
        "    h, w, _ = image.shape\n",
        "\n",
        "    for box_num, box in enumerate(bboxes):\n",
        "        x1, y1, x2, y2 = yolo2bbox(box)\n",
        "\n",
        "        # denormalize the coordinates\n",
        "        xmin = int(x1*w)\n",
        "        ymin = int(y1*h)\n",
        "        xmax = int(x2*w)\n",
        "        ymax = int(y2*h)\n",
        "\n",
        "        width = xmax - xmin\n",
        "        height = ymax - ymin\n",
        "\n",
        "        cv2.rectangle(image, (xmin, ymin), (xmax, ymax), color=(0, 0, 255), thickness=6) \n",
        "        cv2.putText(image, class_names[int(labels[box_num])], (xmin+1, ymin-10), cv2.FONT_HERSHEY_SIMPLEX, 2, (0, 255, 0), 10)\n",
        "\n",
        "    return image"
      ],
      "metadata": {
        "id": "VUPbok6_Tvh9"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to plot images with the bounding boxes.\n",
        "def plot(image_paths, label_paths):\n",
        "    all_training_images = glob.glob(image_paths)\n",
        "    all_training_labels = glob.glob(label_paths)\n",
        "    all_training_images.sort()\n",
        "    all_training_labels.sort()\n",
        "    \n",
        "    plt.figure(figsize=(21, 12))\n",
        "    for i in range(4):\n",
        "        image = cv2.imread(all_training_images[i+10])\n",
        "\n",
        "        with open(all_training_labels[i+10], 'r') as f:\n",
        "            bboxes = []\n",
        "            labels = []\n",
        "            label_lines = f.readlines()\n",
        "            for label_line in label_lines:\n",
        "                label = label_line[0]\n",
        "                bbox_string = label_line[2:]\n",
        "                x_c, y_c, w, h = bbox_string.split(' ')\n",
        "                x_c = float(x_c)\n",
        "                y_c = float(y_c)\n",
        "                w = float(w)\n",
        "                h = float(h)\n",
        "                bboxes.append([x_c, y_c, w, h])\n",
        "                labels.append(label)\n",
        "        result_image = plot_box(image, bboxes, labels)\n",
        "        plt.subplot(2, 2, i+1)\n",
        "        plt.imshow(result_image[:, :, ::-1])\n",
        "        plt.axis('off')\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "vuX2mL7mWrHx"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot(image_paths='data/Traffic Dataset/images/train/*', \n",
        "     label_paths='data/Traffic Dataset/labels/train/*')"
      ],
      "metadata": {
        "id": "j2XkdNJcW7rZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train Model"
      ],
      "metadata": {
        "id": "w0l848INZgru"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Hyperparameter"
      ],
      "metadata": {
        "id": "SehqSxxnaVGv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "TRAIN = True\n",
        "EPOCHS = 5"
      ],
      "metadata": {
        "id": "ftamh0kjZrZ_"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Log Utility Function"
      ],
      "metadata": {
        "id": "z7T8Z6QrZkCS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "LOG_DIR = 'runs/train'"
      ],
      "metadata": {
        "id": "iEVWWWf3aJ2r"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def monitor_tensorboard():\n",
        "    %load_ext tensorboard\n",
        "    %tensorboard --logdir {LOG_DIR}"
      ],
      "metadata": {
        "id": "1R7xwk-WaCzw"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Directory to store train / inference results\n",
        "def set_res_dir():\n",
        "    res_dir_count = len(glob.glob(LOG_DIR + '/*'))\n",
        "    print(f\"Current number of result directories: {res_dir_count}\")\n",
        "\n",
        "    if TRAIN:\n",
        "        RES_DIR = f\"results_{res_dir_count+1}\"\n",
        "        print(RES_DIR)\n",
        "    else:\n",
        "        RES_DIR = f\"results_{res_dir_count}\"\n",
        "\n",
        "    return RES_DIR"
      ],
      "metadata": {
        "id": "4CvOIbawZiLn"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Train"
      ],
      "metadata": {
        "id": "n4bXHsdcacMu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "monitor_tensorboard()\n",
        "RES_DIR = set_res_dir()"
      ],
      "metadata": {
        "id": "CvPrOGMradGs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# YOLOv5m\n",
        "if TRAIN:\n",
        "    !python train.py --data data/data.yaml --weights yolov5m.pt --img 640 --epochs {EPOCHS} --batch-size 16 --name {RES_DIR}"
      ],
      "metadata": {
        "id": "phz6Ie8LcS99"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# YOLOv5m (Transfer Learning. Freeze first 15 layers.)\n",
        "if TRAIN:\n",
        "    !python train.py --data data/data.yaml --weights yolov5m.pt --img 640 --epochs {EPOCHS} --batch-size 16 --name {RES_DIR} \\\n",
        "    --freeze 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14"
      ],
      "metadata": {
        "id": "lSDTIqt2cZON"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# YOLOv5s\n",
        "if TRAIN:\n",
        "    !python train.py --data data/data.yaml --weights yolov5s.pt --img 640 --epochs {EPOCHS} --batch-size 16 --name {RES_DIR}"
      ],
      "metadata": {
        "id": "N6JzcV7gahcZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Evaluation"
      ],
      "metadata": {
        "id": "YVktVCQPfKDF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to show validation predictions saved during training.\n",
        "def show_valid_results(RES_DIR):\n",
        "    EXP_PATH = os.path.join(LOG_DIR, RES_DIR)\n",
        "    validation_pred_images = glob.glob(f\"{EXP_PATH}/*_pred.jpg\")\n",
        "\n",
        "    for pred_image in validation_pred_images:\n",
        "        image = cv2.imread(pred_image)\n",
        "        plt.figure(figsize=(19, 16))\n",
        "        plt.imshow(image[:, :, ::-1])\n",
        "        plt.axis('off')\n",
        "        plt.show()"
      ],
      "metadata": {
        "id": "An2UmmGpde42"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "show_valid_results(RES_DIR)"
      ],
      "metadata": {
        "id": "03UHzwFefNCa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Inference"
      ],
      "metadata": {
        "id": "qEQRo3kjdd8W"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Download Inference Data"
      ],
      "metadata": {
        "id": "d3rcWLB1dfVY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ZIP_FPATH = 'data/inference_data.zip'\n",
        "DATA_DIR = 'data'"
      ],
      "metadata": {
        "id": "NMdsFCh3fnYZ"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "download_file('https://learnopencv.s3.us-west-2.amazonaws.com/yolov5_inference_data.zip', ZIP_FPATH)"
      ],
      "metadata": {
        "id": "2gH49RhVfu3r"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip -q {ZIP_FPATH} -d {DATA_DIR}"
      ],
      "metadata": {
        "id": "hMEN5NL4fbon"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Inference Utility Function"
      ],
      "metadata": {
        "id": "JFkRL0D0f-8Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "DETECT_DIR = 'runs/detect'"
      ],
      "metadata": {
        "id": "tgWzgxyDgNF2"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Helper function for inference on images.\n",
        "def inference(RES_DIR, data_path):\n",
        "    # Directory to store inference results.\n",
        "    infer_dir_count = len(glob.glob(DETECT_DIR + '/*'))\n",
        "    INFER_DIR = f\"inference_{infer_dir_count+1}\"\n",
        "\n",
        "    # Inference on images.\n",
        "    !python detect.py --weights {LOG_DIR}/{RES_DIR}/weights/best.pt --source {data_path} --name {INFER_DIR}\n",
        "\n",
        "    return INFER_DIR"
      ],
      "metadata": {
        "id": "k2JiyzqUdiSr"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualize inference images.\n",
        "def visualize(INFER_DIR):\n",
        "    INFER_PATH = os.path.join(DETECT_DIR, INFER_DIR)\n",
        "\n",
        "    infer_images = glob.glob(f\"{INFER_PATH}/*.jpg\")\n",
        "    for pred_image in infer_images:\n",
        "        image = cv2.imread(pred_image)\n",
        "        plt.figure(figsize=(19, 16))\n",
        "        plt.imshow(image[:, :, ::-1])\n",
        "        plt.axis('off')\n",
        "        plt.show()"
      ],
      "metadata": {
        "id": "4BX7oeD1djb3"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Inference on images.\n",
        "IMAGE_INFER_DIR = inference(RES_DIR, 'data/inference_images')\n",
        "visualize(IMAGE_INFER_DIR)"
      ],
      "metadata": {
        "id": "JfnW40_xdvdN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Inference on videos\n",
        "inference(RES_DIR, 'data/inference_videos')"
      ],
      "metadata": {
        "id": "FcAl5AtMdwzO"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}